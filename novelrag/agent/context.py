from abc import ABC, abstractmethod
import json
from typing import Dict, List

from novelrag.agent.execution import StepOutcome, StepDefinition
from novelrag.agent.tool import LLMToolMixin
from novelrag.llm.types import ChatLLM
from novelrag.template import TemplateEnvironment


class PursuitContext(ABC):
    """
    Context for the pursuit agent.
    This class is used to store the context of the pursuit agent.
    """

    @abstractmethod
    async def store_context(self, step: StepOutcome, future_steps: list[StepDefinition]) -> None:
        """
        Store the context of the pursuit agent.

        :param step: The step outcome to store in the context.
        :param future_steps: List of future step definitions that may be relevant.
        """
        raise NotImplementedError()

    @abstractmethod
    async def retrieve_context(self, step: StepDefinition, max_facets: int = 3) -> list[str]:
        """
        Retrieve the context for a given step definition.

        :param step: The step definition to retrieve context for.
        :param max_facets: The maximum number of context facets to retrieve.
        :return: A list of context strings.
        """
        raise NotImplementedError("Context retrieval not implemented yet.")


class LLMPursuitContext(LLMToolMixin, PursuitContext):
    """
    LLM-based implementation of PursuitContext that uses knowledge facets to organize information.

    This implementation stores contexts in a dictionary where:
    - Keys are different knowledge facets (5-10 word descriptive phrases generated by LLM)
    - Values are lists of knowledge extracted from step results

    Knowledge facets can range from:
    - Generic concepts: "main plot outline development", "character relationship dynamics"
    - Specific items: "character Sarah Chen detective background", "Victorian London crime patterns"
    - Detailed aspects: "Sarah Chen forensic expertise and language skills", "father murder case motivation details"

    Uses LLM to:
    1. Extract knowledge from step outcomes into different facets, considering future steps
    2. Select relevant facets when retrieving context
    """

    def __init__(self, template_env: TemplateEnvironment, chat_llm: ChatLLM):
        """
        Initialize the LLM-based pursuit context.

        :param template_env: Template environment for rendering prompts
        :param chat_llm: Chat LLM for processing contexts and knowledge facets
        """
        super().__init__(template_env, chat_llm)
        self.knowledge_facets: Dict[str, List[str]] = {}

    async def store_context(self, step: StepOutcome, future_steps: list[StepDefinition]) -> None:
        """
        Store the context from a step outcome by extracting knowledge into facets.

        Uses LLM to analyze the step outcome and extract knowledge organized by
        different facets. Considers future steps to determine appropriate facet
        granularity and organization.

        :param step: The step outcome to store in the context.
        :param future_steps: List of future step definitions that may be relevant.
        """
        if not step.results:
            return

        # Prepare step information for context extraction
        step_info = {
            "tool": step.action.tool,
            "intent": step.action.intent,
            "status": step.status.value,
            "results": step.results,
            "progress": step.progress
        }

        # Prepare future steps information to guide facet organization
        future_steps_info = [
            {
                "tool": future_step.tool,
                "intent": future_step.intent
            }
            for future_step in future_steps
        ]

        # Get current facets to provide as reference
        current_facets = list(self.knowledge_facets.keys())

        # Use LLM to extract contexts into knowledge facets
        try:
            extracted_contexts = await self.call_template(
                "extract_pursuit_context.jinja2",
                step_info=step_info,
                future_steps=future_steps_info,
                current_facets=current_facets,
                json_format=True
            )

            # Parse the extracted contexts
            contexts_data = json.loads(extracted_contexts)

            # Store the extracted knowledge by facet
            for facet, knowledge_list in contexts_data.items():
                if facet not in self.knowledge_facets:
                    self.knowledge_facets[facet] = []

                # Add new knowledge items to the facet
                if isinstance(knowledge_list, list):
                    self.knowledge_facets[facet].extend(knowledge_list)
                else:
                    self.knowledge_facets[facet].append(str(knowledge_list))

        except (json.JSONDecodeError, KeyError, Exception) as e:
            # Fallback: store raw results under a generic facet
            generic_facet = f"{step.action.tool} execution results and findings"
            if generic_facet not in self.knowledge_facets:
                self.knowledge_facets[generic_facet] = []
            self.knowledge_facets[generic_facet].extend(step.results)

    async def retrieve_context(self, step: StepDefinition, max_facets: int = 3) -> list[str]:
        """
        Retrieve relevant context for a given step definition.

        Uses LLM to select the most relevant knowledge facets based on the step's
        tool and intent, then returns knowledge from those facets.

        :param step: The step definition to retrieve context for.
        :param max_facets: The maximum number of context facets to retrieve.
        :return: A list of relevant context strings.
        """
        if not self.knowledge_facets:
            return []

        # Prepare step information for facet selection
        step_info = {
            "tool": step.tool,
            "intent": step.intent
        }

        # Get available facets
        available_facets = list(self.knowledge_facets.keys())

        try:
            # Use LLM to select relevant facets, limited by max_facets
            selected_facets_response = await self.call_template(
                "select_relevant_facets.jinja2",
                step_info=step_info,
                available_facets=available_facets,
                max_facets=min(max_facets, len(available_facets)),  # Use max_facets as max facets
                json_format=True
            )

            # Parse the selected facets
            selected_data = json.loads(selected_facets_response)
            selected_facets = selected_data.get("facets", [])

        except (json.JSONDecodeError, KeyError, Exception):
            # Fallback: use available facets limited by max_facets
            selected_facets = available_facets[:max_facets]

        # Collect all knowledge from the selected facets (limited by max_facets)
        collected_context = []
        for facet in selected_facets[:max_facets]:  # Ensure we don't exceed max_facets
            if facet in self.knowledge_facets:
                # Add all knowledge from this facet to the merged list
                facet_knowledge = self.knowledge_facets[facet]
                collected_context.extend(facet_knowledge)

        return collected_context

    def get_all_facets(self) -> Dict[str, List[str]]:
        """
        Get all stored knowledge facets and their information.

        :return: Dictionary mapping facets to their knowledge lists.
        """
        return self.knowledge_facets.copy()

    def clear_context(self) -> None:
        """
        Clear all stored contexts.
        """
        self.knowledge_facets.clear()

    def get_facet_summary(self) -> Dict[str, int]:
        """
        Get a summary of knowledge facets and their information counts.

        :return: Dictionary mapping facets to their knowledge counts.
        """
        return {facet: len(knowledge) for facet, knowledge in self.knowledge_facets.items()}
